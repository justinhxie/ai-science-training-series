We can train LLMs to read scientific literature, and since LLMs can analyze the meaning of sentences and paragraphs, they can quickly grasp the gist of the literature. If we train LLMs on a large corpus of specific literature and then have them read a target document based on this knowledge, it shouldn't be a problem for them to analyze it and suggest improvements or further scientific research. For example, by training LLMs on a vast collection of machine learning articles, once the training is complete, LLMs will undoubtedly have a thorough understanding of machine learning concepts. We can then ask LLMs to provide various methods to enhance the speed of machine learning or improve model training.